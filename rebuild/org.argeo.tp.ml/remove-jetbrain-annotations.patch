diff -crB src/jllama/src/main/java/de/kherud/llama/LlamaIterable.java de.kherud.llama/src/de/kherud/llama/LlamaIterable.java
*** src/jllama/src/main/java/de/kherud/llama/LlamaIterable.java	2024-08-15 17:35:49.059197840 +0200
--- de.kherud.llama/src/de/kherud/llama/LlamaIterable.java	2024-08-15 17:45:43.971905905 +0200
***************
*** 1,14 ****
  package de.kherud.llama;
  
- import org.jetbrains.annotations.NotNull;
- 
  /**
   * An iterable used by {@link LlamaModel#generate(InferenceParameters)} that specifically returns a {@link LlamaIterator}.
   */
  @FunctionalInterface
  public interface LlamaIterable extends Iterable<LlamaOutput> {
  
-     @NotNull
      @Override
      LlamaIterator iterator();
  
--- 1,11 ----
diff -crB src/jllama/src/main/java/de/kherud/llama/LlamaLoader.java de.kherud.llama/src/de/kherud/llama/LlamaLoader.java
*** src/jllama/src/main/java/de/kherud/llama/LlamaLoader.java	2024-08-15 17:35:49.059197840 +0200
--- de.kherud.llama/src/de/kherud/llama/LlamaLoader.java	2024-08-15 17:46:01.588281158 +0200
***************
*** 28,35 ****
  import java.util.List;
  import java.util.stream.Stream;
  
- import org.jetbrains.annotations.Nullable;
- 
  /**
   * Set the system properties, de.kherud.llama.lib.path, de.kherud.llama.lib.name, appropriately so that the
   * library can find *.dll, *.dylib and *.so files, according to the current OS (win, linux, mac).
--- 28,33 ----
***************
*** 182,188 ****
  		}
  	}
  
- 	@Nullable
  	private static Path extractFile(String sourceDirectory, String fileName, String targetDirectory, boolean addUuid) {
  		String nativeLibraryFilePath = sourceDirectory + "/" + fileName;
  
--- 180,185 ----
diff -crB src/jllama/src/main/java/de/kherud/llama/LlamaModel.java de.kherud.llama/src/de/kherud/llama/LlamaModel.java
*** src/jllama/src/main/java/de/kherud/llama/LlamaModel.java	2024-08-15 17:35:49.059197840 +0200
--- de.kherud.llama/src/de/kherud/llama/LlamaModel.java	2024-08-15 17:46:21.072696202 +0200
***************
*** 1,7 ****
  package de.kherud.llama;
  
  import de.kherud.llama.args.LogFormat;
- import org.jetbrains.annotations.Nullable;
  
  import java.lang.annotation.Native;
  import java.nio.charset.StandardCharsets;
--- 1,6 ----
***************
*** 108,114 ****
  	 * @param format the log format to use
  	 * @param callback a method to call for log messages
  	 */
! 	public static native void setLogger(LogFormat format, @Nullable BiConsumer<LogLevel, String> callback);
  
  	@Override
  	public void close() {
--- 107,113 ----
  	 * @param format the log format to use
  	 * @param callback a method to call for log messages
  	 */
! 	public static native void setLogger(LogFormat format, BiConsumer<LogLevel, String> callback);
  
  	@Override
  	public void close() {
diff -crB src/jllama/src/main/java/de/kherud/llama/LlamaOutput.java de.kherud.llama/src/de/kherud/llama/LlamaOutput.java
*** src/jllama/src/main/java/de/kherud/llama/LlamaOutput.java	2024-08-15 17:35:49.059197840 +0200
--- de.kherud.llama/src/de/kherud/llama/LlamaOutput.java	2024-08-15 17:46:42.069143454 +0200
***************
*** 1,7 ****
  package de.kherud.llama;
  
- import org.jetbrains.annotations.NotNull;
- 
  import java.nio.charset.StandardCharsets;
  import java.util.Map;
  
--- 1,5 ----
***************
*** 15,32 ****
       * The last bit of generated text that is representable as text (i.e., cannot be individual utf-8 multibyte code
       * points).
       */
-     @NotNull
      public final String text;
  
      /**
       * Note, that you have to configure {@link InferenceParameters#setNProbs(int)} in order for probabilities to be returned.
       */
-     @NotNull
      public final Map<String, Float> probabilities;
  
      final boolean stop;
  
!     LlamaOutput(byte[] generated, @NotNull Map<String, Float> probabilities, boolean stop) {
          this.text = new String(generated, StandardCharsets.UTF_8);
          this.probabilities = probabilities;
          this.stop = stop;
--- 13,28 ----
       * The last bit of generated text that is representable as text (i.e., cannot be individual utf-8 multibyte code
       * points).
       */
      public final String text;
  
      /**
       * Note, that you have to configure {@link InferenceParameters#setNProbs(int)} in order for probabilities to be returned.
       */
      public final Map<String, Float> probabilities;
  
      final boolean stop;
  
!     LlamaOutput(byte[] generated, Map<String, Float> probabilities, boolean stop) {
          this.text = new String(generated, StandardCharsets.UTF_8);
          this.probabilities = probabilities;
          this.stop = stop;
